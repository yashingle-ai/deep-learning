{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df0e8869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        .   \\n    .   .   .\\n.   .   .   .   .\\n.   .   .   .   .   (.)-> y_pred  \\n    .   .   .\\n        .\\n\\n\\nhere assume if i want to updates weights between input layer and hidden layer then \\nits very difficult and in some cases its impossible so for solving this problem we are using autograd feature of PyTorch.\\n\\n\\nAutograd is a core component of PyTorch that provides automatic diffrentiation for tensor operations .\\nit enables gradient computation,which is essential for training machine learning models using optimization \\nalgorithms like gradient descent.\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pyTorch autorgrad\n",
    "\n",
    "\n",
    "# for training any neural network :- \n",
    "# what we are doing\n",
    "# forward passs ->calculate loss ->backward pass -> update the gradients \n",
    "# loss function :- \n",
    "# loss function = -[y_pred.ln(y_pred)]+(1-y_target).ln(1-y_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        .   \n",
    "    .   .   .\n",
    ".   .   .   .   .\n",
    ".   .   .   .   .   (.)-> y_pred  \n",
    "    .   .   .\n",
    "        .\n",
    "\n",
    "\n",
    "here assume if i want to updates weights between input layer and hidden layer then \n",
    "its very difficult and in some cases its impossible so for solving this problem we are using autograd feature of PyTorch.\n",
    "\n",
    "\n",
    "Autograd is a core component of PyTorch that provides automatic diffrentiation for tensor operations .\n",
    "it enables gradient computation,which is essential for training machine learning models using optimization \n",
    "algorithms like gradient descent.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85734439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')\n",
    "\n",
    "x = torch.tensor(4.0, requires_grad= True,device = device) # setting up the requires_grad = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6caa50a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7f77a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x17fd38f2da0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y.grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "589b2ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2879, device='cuda:0', grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.sin(y)\n",
    "z\n",
    "# x -> y -> z  //  here with the help of computation graph pytorch try to remember the backword function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19e6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109429b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.6613, device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5da3eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3116\\3447458826.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  y.grad\n"
     ]
    }
   ],
   "source": [
    "# here if we are trying to acces the intermidiate gradients then we got the error \n",
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3ee0456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing grad\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28224e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "341a070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5713db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cee06cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d17d3c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c091000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "033cad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad602ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 - requires_grad_(False)\n",
    "# option 2 - detach()\n",
    "# option 3 - torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666f48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
