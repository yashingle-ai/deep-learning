{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f79a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6575ec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from C:\\Users\\Lenovo\\_netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myash-ingle002\u001b[0m (\u001b[33myash-ingle002-sardar-vallabhbhai-national-institute-of-t\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\OneDrive\\Desktop\\deep Learning\\CNN\\wandb\\run-20260207_151750-ff96qfe1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers/runs/ff96qfe1' target=\"_blank\">magic-haze-1</a></strong> to <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers' target=\"_blank\">https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers/runs/ff96qfe1' target=\"_blank\">https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/MobileNet-flowers/runs/ff96qfe1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================\n",
    "# STEP 0: Initialize wandb\n",
    "# =======================\n",
    "wandb.init(project=\"MobileNet-flowers\", config={\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"MobileNet\",\n",
    "    \"pretrained\": True,\n",
    "    \"input_size\": 224\n",
    "})\n",
    "\n",
    "# Shortcut to config values\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b3b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "# Transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset path (YOUR CURRENT LOCATION)\n",
    "\n",
    "data_dir = r\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\deep Learning\\Dataset\\flowers\"\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "\n",
    "\n",
    "# Train / Validation Split\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Assign transforms AFTER split (important!)\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb3c468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to C:\\Users\\Lenovo/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-7ebf99e0.pth\n",
      "100%|██████████| 13.6M/13.6M [00:08<00:00, 1.76MB/s]\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# STEP 2: Load Pretrained MobileNetV2\n",
    "# ===========================\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# Replace the final classifier layer for 5-class flower classification\n",
    "model.classifier[1] = nn.Linear(model.last_channel, 5)\n",
    "\n",
    "# Freeze all parameters except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Watch the model's weights and gradients with wandb\n",
    "wandb.watch(model, log=\"all\", log_freq=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0fe29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# STEP 3: Loss & Optimizer\n",
    "# ===================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8a593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            batch_correct = (preds == labels).sum().item()\n",
    "            train_correct += batch_correct\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            # Print every 10 batches\n",
    "            if (i + 1) % 10 == 0:\n",
    "                batch_acc = batch_correct / labels.size(0)\n",
    "                print(f\"[Batch {i+1}/{len(train_loader)}] Loss: {loss.item():.4f}, Batch Acc: {batch_acc:.4f}\")\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": running_loss, \"train_accuracy\": train_acc})\n",
    "        print(f\"Epoch {epoch+1} Summary - Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        wandb.log({\"epoch\": epoch + 1, \"val_accuracy\": val_acc})\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce66c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 1.4825, Batch Acc: 0.5000\n",
      "[Batch 20/216] Loss: 1.1655, Batch Acc: 0.7500\n",
      "[Batch 30/216] Loss: 1.0663, Batch Acc: 0.6875\n",
      "[Batch 40/216] Loss: 0.9609, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 1.0372, Batch Acc: 0.6250\n",
      "[Batch 60/216] Loss: 0.7436, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 1.1882, Batch Acc: 0.4375\n",
      "[Batch 80/216] Loss: 0.7585, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.9848, Batch Acc: 0.6250\n",
      "[Batch 100/216] Loss: 0.4569, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.9829, Batch Acc: 0.6250\n",
      "[Batch 120/216] Loss: 0.6307, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.7744, Batch Acc: 0.8125\n",
      "[Batch 140/216] Loss: 0.3895, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.4708, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.4461, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.5041, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.4574, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.4207, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.8550, Batch Acc: 0.6875\n",
      "[Batch 210/216] Loss: 0.4151, Batch Acc: 0.8750\n",
      "Epoch 1 Summary - Loss: 166.0218, Train Accuracy: 0.7663\n",
      "Validation Accuracy: 0.8634\n",
      "\n",
      "Epoch 2/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2603, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.3696, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.4936, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.4851, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.5074, Batch Acc: 0.7500\n",
      "[Batch 60/216] Loss: 0.5632, Batch Acc: 0.7500\n",
      "[Batch 70/216] Loss: 0.5956, Batch Acc: 0.7500\n",
      "[Batch 80/216] Loss: 0.2497, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.3673, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.5308, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.4170, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.5101, Batch Acc: 0.7500\n",
      "[Batch 130/216] Loss: 0.6418, Batch Acc: 0.7500\n",
      "[Batch 140/216] Loss: 0.3424, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2650, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.7658, Batch Acc: 0.6875\n",
      "[Batch 170/216] Loss: 0.3300, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.4588, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.5982, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.4469, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.6004, Batch Acc: 0.7500\n",
      "Epoch 2 Summary - Loss: 101.0055, Train Accuracy: 0.8477\n",
      "Validation Accuracy: 0.8692\n",
      "\n",
      "Epoch 3/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2999, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.3718, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.4469, Batch Acc: 0.7500\n",
      "[Batch 40/216] Loss: 0.3219, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.7357, Batch Acc: 0.7500\n",
      "[Batch 60/216] Loss: 0.2468, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.5509, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.3755, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.2629, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.2010, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.2082, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2241, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.4781, Batch Acc: 0.7500\n",
      "[Batch 140/216] Loss: 0.1106, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1501, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.3932, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.3815, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.6040, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.3234, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.5855, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.3633, Batch Acc: 0.8750\n",
      "Epoch 3 Summary - Loss: 89.4592, Train Accuracy: 0.8593\n",
      "Validation Accuracy: 0.8819\n",
      "\n",
      "Epoch 4/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2270, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.5043, Batch Acc: 0.7500\n",
      "[Batch 30/216] Loss: 0.3494, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1735, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.4065, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.3853, Batch Acc: 0.7500\n",
      "[Batch 70/216] Loss: 0.1860, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.2281, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.6596, Batch Acc: 0.7500\n",
      "[Batch 100/216] Loss: 0.4213, Batch Acc: 0.7500\n",
      "[Batch 110/216] Loss: 0.0915, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0984, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.4586, Batch Acc: 0.7500\n",
      "[Batch 140/216] Loss: 0.2257, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2946, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2594, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.3992, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.5355, Batch Acc: 0.7500\n",
      "[Batch 190/216] Loss: 0.6001, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.2512, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.3667, Batch Acc: 0.8125\n",
      "Epoch 4 Summary - Loss: 77.9141, Train Accuracy: 0.8772\n",
      "Validation Accuracy: 0.8808\n",
      "\n",
      "Epoch 5/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.7081, Batch Acc: 0.8125\n",
      "[Batch 20/216] Loss: 0.1911, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1734, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.4326, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.1768, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2702, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.5174, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.2409, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.2390, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1802, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.4206, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.2278, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.3564, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1611, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.2363, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1810, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2811, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.3758, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.3648, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.2960, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.2674, Batch Acc: 0.8750\n",
      "Epoch 5 Summary - Loss: 74.7763, Train Accuracy: 0.8766\n",
      "Validation Accuracy: 0.8970\n",
      "\n",
      "Epoch 6/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4244, Batch Acc: 0.8125\n",
      "[Batch 20/216] Loss: 0.5448, Batch Acc: 0.7500\n",
      "[Batch 30/216] Loss: 0.5536, Batch Acc: 0.8125\n",
      "[Batch 40/216] Loss: 0.5020, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.2740, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.3779, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.4686, Batch Acc: 0.7500\n",
      "[Batch 80/216] Loss: 0.2009, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.3104, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.3504, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2699, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.5972, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.1533, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2907, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.4971, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.2961, Batch Acc: 0.8125\n",
      "[Batch 170/216] Loss: 0.1987, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1786, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.5183, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3718, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.4881, Batch Acc: 0.9375\n",
      "Epoch 6 Summary - Loss: 72.6435, Train Accuracy: 0.8839\n",
      "Validation Accuracy: 0.8889\n",
      "\n",
      "Epoch 7/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1559, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.4055, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1442, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.6126, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.2255, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.6156, Batch Acc: 0.6875\n",
      "[Batch 70/216] Loss: 0.3993, Batch Acc: 0.7500\n",
      "[Batch 80/216] Loss: 0.4216, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.1878, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1987, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.3572, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.4262, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.1751, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2240, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1168, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.3657, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.2343, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1471, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2987, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.2305, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.3632, Batch Acc: 0.8750\n",
      "Epoch 7 Summary - Loss: 70.4991, Train Accuracy: 0.8868\n",
      "Validation Accuracy: 0.8900\n",
      "\n",
      "Epoch 8/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3981, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1717, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.1821, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.2004, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1773, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.3686, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.3650, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1141, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.4499, Batch Acc: 0.8125\n",
      "[Batch 100/216] Loss: 0.3329, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.1282, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.2226, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.3375, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.3888, Batch Acc: 0.8125\n",
      "[Batch 150/216] Loss: 0.4528, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.3731, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1198, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1855, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2729, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3315, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.1829, Batch Acc: 1.0000\n",
      "Epoch 8 Summary - Loss: 70.9158, Train Accuracy: 0.8885\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 9/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4130, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.2675, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1378, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.2293, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.2130, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.3821, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.4473, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.2212, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.3425, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.4008, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.4898, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.2644, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1364, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2020, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2096, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1303, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1933, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.3418, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.3324, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.2239, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2675, Batch Acc: 0.8750\n",
      "Epoch 9 Summary - Loss: 67.2503, Train Accuracy: 0.8983\n",
      "Validation Accuracy: 0.8877\n",
      "\n",
      "Epoch 10/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2657, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.4281, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1930, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.4711, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.0930, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1974, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.3132, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.1779, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.2462, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.2579, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.5621, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.4065, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.2318, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1803, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.2190, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.3873, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.2552, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1317, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2576, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2151, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0607, Batch Acc: 1.0000\n",
      "Epoch 10 Summary - Loss: 64.5175, Train Accuracy: 0.8989\n",
      "Validation Accuracy: 0.8900\n",
      "\n",
      "Epoch 11/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1540, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.2837, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0886, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1507, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.3003, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.5206, Batch Acc: 0.7500\n",
      "[Batch 70/216] Loss: 0.4911, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.4874, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.3489, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.3180, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.3205, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.2304, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.4762, Batch Acc: 0.8125\n",
      "[Batch 140/216] Loss: 0.1903, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1004, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.3199, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2123, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.4318, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.5919, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3745, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.3492, Batch Acc: 0.9375\n",
      "Epoch 11 Summary - Loss: 62.6874, Train Accuracy: 0.9039\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 12/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3677, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1009, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.3117, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.2532, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.3445, Batch Acc: 0.7500\n",
      "[Batch 60/216] Loss: 0.0740, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0888, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1670, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.2457, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1422, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1562, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1012, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1611, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.3197, Batch Acc: 0.8125\n",
      "[Batch 150/216] Loss: 0.1291, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.4500, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2867, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0501, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1496, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.2274, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.3180, Batch Acc: 0.8750\n",
      "Epoch 12 Summary - Loss: 58.7948, Train Accuracy: 0.9070\n",
      "Validation Accuracy: 0.8877\n",
      "\n",
      "Epoch 13/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2218, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1875, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2737, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.3507, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.2855, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.2649, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3718, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.2103, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.2674, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0528, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.3587, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0476, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0912, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.3074, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.2262, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.2350, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.4301, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.1555, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2023, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.3582, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.3709, Batch Acc: 0.8750\n",
      "Epoch 13 Summary - Loss: 58.7234, Train Accuracy: 0.9030\n",
      "Validation Accuracy: 0.8970\n",
      "\n",
      "Epoch 14/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.6134, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.2779, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2928, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.2133, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0770, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.5423, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3167, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.2242, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1518, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.4129, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2824, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.1199, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.7301, Batch Acc: 0.6875\n",
      "[Batch 140/216] Loss: 0.2140, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2673, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.1855, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1844, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.2345, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2457, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.2070, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.1858, Batch Acc: 0.9375\n",
      "Epoch 14 Summary - Loss: 58.1284, Train Accuracy: 0.9117\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 15/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2666, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.3162, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.5895, Batch Acc: 0.7500\n",
      "[Batch 40/216] Loss: 0.2582, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.1684, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.0812, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.5930, Batch Acc: 0.7500\n",
      "[Batch 80/216] Loss: 0.1316, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.3241, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1488, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1445, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2283, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2249, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.3930, Batch Acc: 0.8125\n",
      "[Batch 150/216] Loss: 0.3147, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.6066, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.2046, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0745, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.3672, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1838, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.4119, Batch Acc: 0.7500\n",
      "Epoch 15 Summary - Loss: 55.8119, Train Accuracy: 0.9027\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 16/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1309, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.3773, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.3384, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.4340, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.5626, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.5221, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3840, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.7275, Batch Acc: 0.7500\n",
      "[Batch 90/216] Loss: 0.5481, Batch Acc: 0.7500\n",
      "[Batch 100/216] Loss: 0.2049, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.1961, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.3417, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1919, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1175, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.3793, Batch Acc: 0.7500\n",
      "[Batch 160/216] Loss: 0.1664, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1698, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.4972, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.2059, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1467, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1674, Batch Acc: 0.8750\n",
      "Epoch 16 Summary - Loss: 60.7581, Train Accuracy: 0.8972\n",
      "Validation Accuracy: 0.8935\n",
      "\n",
      "Epoch 17/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2970, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1315, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2995, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.3640, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.4570, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.1652, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.4221, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.2366, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1216, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1972, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2481, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.3500, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.1151, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1643, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2984, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.3038, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2265, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.3695, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.3559, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1245, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1456, Batch Acc: 0.9375\n",
      "Epoch 17 Summary - Loss: 56.9500, Train Accuracy: 0.9073\n",
      "Validation Accuracy: 0.8877\n",
      "\n",
      "Epoch 18/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1297, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1366, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.3671, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.2237, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.2826, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.1317, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.2180, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2625, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1921, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.3202, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.5116, Batch Acc: 0.8125\n",
      "[Batch 120/216] Loss: 0.2138, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.3811, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.2268, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2853, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2632, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2653, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.0584, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.5073, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.6557, Batch Acc: 0.7500\n",
      "[Batch 210/216] Loss: 0.0586, Batch Acc: 1.0000\n",
      "Epoch 18 Summary - Loss: 58.4697, Train Accuracy: 0.9021\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 19/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2075, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.3112, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1240, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.3025, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.4050, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.1281, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1222, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.2212, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1626, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1050, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1997, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1621, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0559, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0624, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0256, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2138, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.3515, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.0952, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1324, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1899, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.4190, Batch Acc: 0.9375\n",
      "Epoch 19 Summary - Loss: 53.7775, Train Accuracy: 0.9143\n",
      "Validation Accuracy: 0.8981\n",
      "\n",
      "Epoch 20/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0800, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1069, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2708, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1678, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.2351, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.4401, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3047, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.0492, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.4845, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.2290, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.4252, Batch Acc: 0.8125\n",
      "[Batch 120/216] Loss: 0.2506, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2270, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1895, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1863, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.7618, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.3975, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.2579, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.1933, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0529, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.4242, Batch Acc: 0.7500\n",
      "Epoch 20 Summary - Loss: 54.0196, Train Accuracy: 0.9131\n",
      "Validation Accuracy: 0.8947\n",
      "\n",
      "Epoch 21/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1229, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.3949, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.3256, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.4829, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.1714, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1644, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0620, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.4767, Batch Acc: 0.7500\n",
      "[Batch 90/216] Loss: 0.1176, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1150, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2450, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0709, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1820, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1965, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1273, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.5239, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.2977, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.2445, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.2510, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1489, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0799, Batch Acc: 0.9375\n",
      "Epoch 21 Summary - Loss: 55.9628, Train Accuracy: 0.9082\n",
      "Validation Accuracy: 0.8947\n",
      "\n",
      "Epoch 22/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1261, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1430, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2717, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1652, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.1257, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.4606, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.5058, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.1246, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.5091, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.2380, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2944, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.2189, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.1210, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2930, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.3116, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.3403, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.1659, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.4802, Batch Acc: 0.7500\n",
      "[Batch 190/216] Loss: 0.1605, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.3660, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2374, Batch Acc: 0.8750\n",
      "Epoch 22 Summary - Loss: 51.9110, Train Accuracy: 0.9140\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 23/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3042, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.3762, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.1128, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0633, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.2889, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1334, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1077, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1592, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0904, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1487, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1390, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1308, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1977, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.3936, Batch Acc: 0.8125\n",
      "[Batch 150/216] Loss: 0.2962, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2363, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.3730, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.3010, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.4066, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1965, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.1430, Batch Acc: 0.9375\n",
      "Epoch 23 Summary - Loss: 50.5420, Train Accuracy: 0.9154\n",
      "Validation Accuracy: 0.9005\n",
      "\n",
      "Epoch 24/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0959, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.3968, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1773, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1610, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.5848, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.3261, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1288, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1139, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.2138, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.4842, Batch Acc: 0.7500\n",
      "[Batch 110/216] Loss: 0.1506, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2592, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.1070, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0902, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0990, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2328, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.4139, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.4994, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.4762, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.2834, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.2469, Batch Acc: 0.8750\n",
      "Epoch 24 Summary - Loss: 51.0389, Train Accuracy: 0.9221\n",
      "Validation Accuracy: 0.8912\n",
      "\n",
      "Epoch 25/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1042, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0856, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.6347, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1831, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.2786, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.3553, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.0984, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1239, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.2994, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.5762, Batch Acc: 0.6875\n",
      "[Batch 110/216] Loss: 0.2290, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0492, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.3154, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.4182, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.1616, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.4875, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.0472, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1561, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.3622, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3808, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.3003, Batch Acc: 0.8125\n",
      "Epoch 25 Summary - Loss: 52.9284, Train Accuracy: 0.9131\n",
      "Validation Accuracy: 0.8970\n",
      "\n",
      "Epoch 26/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4092, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.3109, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.2815, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.5259, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.1785, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1353, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.5354, Batch Acc: 0.6875\n",
      "[Batch 80/216] Loss: 0.4065, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0865, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.3092, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2742, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.1000, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.5198, Batch Acc: 0.8125\n",
      "[Batch 140/216] Loss: 0.3830, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.3194, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.5522, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.1306, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.3407, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.3376, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1592, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.4576, Batch Acc: 0.8125\n",
      "Epoch 26 Summary - Loss: 54.5447, Train Accuracy: 0.9108\n",
      "Validation Accuracy: 0.8993\n",
      "\n",
      "Epoch 27/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3200, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.3748, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.4938, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1706, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1797, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.2768, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.4184, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2578, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.0922, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2916, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.3699, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.2167, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.1266, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2356, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.1647, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2802, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.1272, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0677, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0870, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1900, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1143, Batch Acc: 0.9375\n",
      "Epoch 27 Summary - Loss: 49.5530, Train Accuracy: 0.9212\n",
      "Validation Accuracy: 0.8993\n",
      "\n",
      "Epoch 28/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1465, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.2435, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.2023, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1722, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.2605, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.0568, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1775, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2202, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.2611, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1461, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0728, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1691, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1360, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0724, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1225, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1344, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0929, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.3782, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.1193, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2494, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.2637, Batch Acc: 0.8750\n",
      "Epoch 28 Summary - Loss: 49.1591, Train Accuracy: 0.9166\n",
      "Validation Accuracy: 0.8970\n",
      "\n",
      "Epoch 29/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4404, Batch Acc: 0.8125\n",
      "[Batch 20/216] Loss: 0.1631, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.2459, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0756, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.4217, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.2455, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.2086, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1518, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.3811, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.4586, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.1081, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.3798, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.1138, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.4436, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.0933, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2975, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.0483, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1442, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1610, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1496, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.4853, Batch Acc: 0.8125\n",
      "Epoch 29 Summary - Loss: 50.2818, Train Accuracy: 0.9178\n",
      "Validation Accuracy: 0.8912\n",
      "\n",
      "Epoch 30/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1182, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0305, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1820, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.0624, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0232, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.3128, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1156, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1513, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1106, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0643, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.2321, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0474, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1912, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.2025, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1060, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2375, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.3246, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.1074, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1361, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1112, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1548, Batch Acc: 0.9375\n",
      "Epoch 30 Summary - Loss: 48.0422, Train Accuracy: 0.9215\n",
      "Validation Accuracy: 0.8947\n",
      "\n",
      "Epoch 31/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4166, Batch Acc: 0.7500\n",
      "[Batch 20/216] Loss: 0.0921, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2133, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1331, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.1940, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1203, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1827, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1753, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.6656, Batch Acc: 0.7500\n",
      "[Batch 100/216] Loss: 0.0891, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.3409, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.1053, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0665, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1345, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3302, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.3126, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.0909, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1601, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2199, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1374, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0472, Batch Acc: 1.0000\n",
      "Epoch 31 Summary - Loss: 48.3698, Train Accuracy: 0.9215\n",
      "Validation Accuracy: 0.8935\n",
      "\n",
      "Epoch 32/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1724, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1869, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.3825, Batch Acc: 0.7500\n",
      "[Batch 40/216] Loss: 0.1383, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.5425, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.3018, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.0666, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1340, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1543, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0856, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1811, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1393, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1819, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1508, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2323, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.1971, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.1632, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0588, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1072, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.4443, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.3871, Batch Acc: 0.8750\n",
      "Epoch 32 Summary - Loss: 53.0731, Train Accuracy: 0.9140\n",
      "Validation Accuracy: 0.8877\n",
      "\n",
      "Epoch 33/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2899, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1615, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.1439, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1107, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.5095, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.3826, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.1956, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1751, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1312, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.2857, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1216, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1294, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1601, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.3897, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0542, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2680, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.0694, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1825, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2483, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.0617, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1373, Batch Acc: 0.9375\n",
      "Epoch 33 Summary - Loss: 52.0125, Train Accuracy: 0.9120\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 34/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1309, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.3405, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.2015, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.3776, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.2769, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.1883, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1527, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0326, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1595, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2670, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2321, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0298, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1635, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2203, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2466, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.3291, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0859, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0947, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2467, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.0278, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2048, Batch Acc: 0.8750\n",
      "Epoch 34 Summary - Loss: 45.8285, Train Accuracy: 0.9256\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 35/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0905, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1383, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0850, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0662, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.5170, Batch Acc: 0.6250\n",
      "[Batch 60/216] Loss: 0.0934, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.3713, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.2503, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.2147, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.5612, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.0306, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1954, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0971, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2058, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1635, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2442, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1412, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0526, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1886, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.3450, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.9717, Batch Acc: 0.6875\n",
      "Epoch 35 Summary - Loss: 46.1392, Train Accuracy: 0.9178\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 36/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3349, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1255, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1491, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0720, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.4372, Batch Acc: 0.7500\n",
      "[Batch 60/216] Loss: 0.3063, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3899, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.4788, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.0335, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2441, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.5010, Batch Acc: 0.8125\n",
      "[Batch 120/216] Loss: 0.5179, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.3303, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1326, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3308, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.3730, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.4227, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.0813, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1252, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.2154, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0971, Batch Acc: 1.0000\n",
      "Epoch 36 Summary - Loss: 49.9364, Train Accuracy: 0.9154\n",
      "Validation Accuracy: 0.8866\n",
      "\n",
      "Epoch 37/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2164, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.0291, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1595, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.2322, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.2591, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.0933, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1681, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0667, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.4252, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.3693, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.1586, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1947, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0739, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1276, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3557, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.1039, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1774, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.5011, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.2266, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1027, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.3609, Batch Acc: 0.9375\n",
      "Epoch 37 Summary - Loss: 47.6023, Train Accuracy: 0.9250\n",
      "Validation Accuracy: 0.8843\n",
      "\n",
      "Epoch 38/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1890, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1176, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2449, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1945, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.3898, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.0533, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.3981, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.2207, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.0636, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2300, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.0567, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1390, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.8031, Batch Acc: 0.7500\n",
      "[Batch 140/216] Loss: 0.0502, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1557, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1128, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0312, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1490, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.4716, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.1689, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.0348, Batch Acc: 1.0000\n",
      "Epoch 38 Summary - Loss: 50.2532, Train Accuracy: 0.9146\n",
      "Validation Accuracy: 0.8912\n",
      "\n",
      "Epoch 39/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1209, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.3889, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.1875, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1878, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0778, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1202, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.2590, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1782, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.1190, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2890, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2323, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.3317, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.3087, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.2356, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.0400, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1224, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0872, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.5798, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.2926, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3607, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1074, Batch Acc: 0.9375\n",
      "Epoch 39 Summary - Loss: 47.9246, Train Accuracy: 0.9189\n",
      "Validation Accuracy: 0.8935\n",
      "\n",
      "Epoch 40/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0404, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1218, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1058, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0885, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.3896, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.1486, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.3683, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0414, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1571, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.3411, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.1656, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.4256, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.0228, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.3890, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1255, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0677, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1854, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.3407, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.0838, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2092, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2250, Batch Acc: 0.9375\n",
      "Epoch 40 Summary - Loss: 48.4778, Train Accuracy: 0.9169\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 41/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1781, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1268, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.1928, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.4881, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.0654, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0514, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0842, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0552, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0238, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1781, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.8920, Batch Acc: 0.7500\n",
      "[Batch 120/216] Loss: 0.1199, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1473, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0345, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1726, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.3547, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2424, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1690, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2455, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.3332, Batch Acc: 0.7500\n",
      "[Batch 210/216] Loss: 0.2017, Batch Acc: 0.8750\n",
      "Epoch 41 Summary - Loss: 48.3726, Train Accuracy: 0.9189\n",
      "Validation Accuracy: 0.8935\n",
      "\n",
      "Epoch 42/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1676, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.2939, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.4386, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.4351, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.0805, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1378, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1543, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1826, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.4584, Batch Acc: 0.6875\n",
      "[Batch 100/216] Loss: 0.2651, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2331, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2557, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.6094, Batch Acc: 0.7500\n",
      "[Batch 140/216] Loss: 0.1087, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.3130, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.2958, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.3200, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.3450, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.2248, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1722, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.1090, Batch Acc: 0.9375\n",
      "Epoch 42 Summary - Loss: 47.6147, Train Accuracy: 0.9201\n",
      "Validation Accuracy: 0.8993\n",
      "\n",
      "Epoch 43/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1898, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.6184, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.4990, Batch Acc: 0.8125\n",
      "[Batch 40/216] Loss: 0.1112, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0741, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0719, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1342, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2135, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.1948, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1342, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.3022, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 1.0053, Batch Acc: 0.6875\n",
      "[Batch 130/216] Loss: 0.0888, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1174, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1820, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1261, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0759, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.3313, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.0832, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0533, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1188, Batch Acc: 0.9375\n",
      "Epoch 43 Summary - Loss: 47.0149, Train Accuracy: 0.9195\n",
      "Validation Accuracy: 0.8981\n",
      "\n",
      "Epoch 44/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1585, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0371, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.3256, Batch Acc: 0.8125\n",
      "[Batch 40/216] Loss: 0.0706, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0723, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2107, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.2743, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.6389, Batch Acc: 0.6875\n",
      "[Batch 90/216] Loss: 0.1046, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1423, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1170, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.3455, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.6161, Batch Acc: 0.8125\n",
      "[Batch 140/216] Loss: 0.1715, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.2579, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.1700, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1081, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.4052, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.1030, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0250, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2394, Batch Acc: 0.8750\n",
      "Epoch 44 Summary - Loss: 53.1931, Train Accuracy: 0.9079\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 45/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4531, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1453, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2781, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.3247, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.1677, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.0764, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1487, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2765, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1436, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.6155, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.3949, Batch Acc: 0.8125\n",
      "[Batch 120/216] Loss: 0.0080, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1974, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.3628, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.0478, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0683, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0975, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1746, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2024, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0884, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2932, Batch Acc: 0.8750\n",
      "Epoch 45 Summary - Loss: 47.0665, Train Accuracy: 0.9206\n",
      "Validation Accuracy: 0.8900\n",
      "\n",
      "Epoch 46/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1482, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.4056, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.2668, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1922, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.3713, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.2435, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.2269, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1336, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0572, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.3295, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.7403, Batch Acc: 0.6250\n",
      "[Batch 120/216] Loss: 0.1331, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.4338, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.2711, Batch Acc: 0.8125\n",
      "[Batch 150/216] Loss: 0.4210, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.1944, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.1203, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1313, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.4018, Batch Acc: 0.7500\n",
      "[Batch 200/216] Loss: 0.1882, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.2753, Batch Acc: 0.8750\n",
      "Epoch 46 Summary - Loss: 48.4641, Train Accuracy: 0.9160\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 47/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2886, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.1413, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.4784, Batch Acc: 0.8125\n",
      "[Batch 40/216] Loss: 0.3961, Batch Acc: 0.8125\n",
      "[Batch 50/216] Loss: 0.0683, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1345, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1109, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0741, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1118, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.5586, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.1156, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0239, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1136, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1672, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0425, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0897, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1037, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.2901, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.5060, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.1542, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.3943, Batch Acc: 0.8750\n",
      "Epoch 47 Summary - Loss: 49.3573, Train Accuracy: 0.9198\n",
      "Validation Accuracy: 0.8970\n",
      "\n",
      "Epoch 48/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1250, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1678, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.0925, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0739, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.2037, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1486, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.0949, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.4161, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.2427, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.0982, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1866, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2178, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1009, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1948, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3029, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.0667, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.2052, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1070, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.0941, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0479, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0346, Batch Acc: 1.0000\n",
      "Epoch 48 Summary - Loss: 51.0736, Train Accuracy: 0.9157\n",
      "Validation Accuracy: 0.8924\n",
      "\n",
      "Epoch 49/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.5800, Batch Acc: 0.8125\n",
      "[Batch 20/216] Loss: 1.1074, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.0742, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.2472, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.0323, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.3825, Batch Acc: 0.7500\n",
      "[Batch 70/216] Loss: 0.2767, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2302, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.2990, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1844, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0887, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2921, Batch Acc: 0.8125\n",
      "[Batch 130/216] Loss: 0.2984, Batch Acc: 0.8125\n",
      "[Batch 140/216] Loss: 0.3236, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.1293, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1234, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0046, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0841, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1642, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.6184, Batch Acc: 0.7500\n",
      "[Batch 210/216] Loss: 0.0039, Batch Acc: 1.0000\n",
      "Epoch 49 Summary - Loss: 49.3195, Train Accuracy: 0.9146\n",
      "Validation Accuracy: 0.8958\n",
      "\n",
      "Epoch 50/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0356, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.2987, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2040, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.2613, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.1822, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.2811, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.1877, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.2222, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1398, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.4668, Batch Acc: 0.7500\n",
      "[Batch 110/216] Loss: 0.2835, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.9142, Batch Acc: 0.7500\n",
      "[Batch 130/216] Loss: 0.1485, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.3560, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1562, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0338, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0987, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1226, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.6323, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.2094, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2211, Batch Acc: 0.9375\n",
      "Epoch 50 Summary - Loss: 47.6353, Train Accuracy: 0.9175\n",
      "Validation Accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# ===================\n",
    "# Train the model\n",
    "# ===================\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, epochs=config.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
