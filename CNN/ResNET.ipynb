{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e31b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from C:\\Users\\Lenovo\\_netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myash-ingle002\u001b[0m (\u001b[33myash-ingle002-sardar-vallabhbhai-national-institute-of-t\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\OneDrive\\Desktop\\deep Learning\\CNN\\wandb\\run-20260207_113738-tpdita93</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers/runs/tpdita93' target=\"_blank\">pleasant-glade-1</a></strong> to <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers' target=\"_blank\">https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers/runs/tpdita93' target=\"_blank\">https://wandb.ai/yash-ingle002-sardar-vallabhbhai-national-institute-of-t/ResNet-flowers/runs/tpdita93</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize wandb\n",
    "\n",
    "wandb.init(project=\"ResNet-flowers\", config={\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"ResNet\",\n",
    "    \"pretrained\": True,\n",
    "    \"input_size\": 224\n",
    "})\n",
    "\n",
    "# Shortcut to config values\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95ea033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "# Transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset path (YOUR CURRENT LOCATION)\n",
    "\n",
    "data_dir = r\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\deep Learning\\Dataset\\flowers\"\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "\n",
    "\n",
    "# Train / Validation Split\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Assign transforms AFTER split (important!)\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb805188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\Lenovo/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:48<00:00, 2.12MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 5)  \n",
    "\n",
    "# Freeze all but final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Watch the model's weights and gradients\n",
    "wandb.watch(model, log=\"all\", log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c18a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            batch_correct = (preds == labels).sum().item()\n",
    "            train_correct += batch_correct\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            # print every 10 batches\n",
    "            if (i + 1) % 10 == 0:\n",
    "                batch_acc = batch_correct / labels.size(0)\n",
    "                print(f\"[Batch {i+1}/{len(train_loader)}] Loss: {loss.item():.4f}, Batch Acc: {batch_acc:.4f}\")\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": running_loss, \"train_accuracy\": train_acc})\n",
    "        print(f\"Epoch {epoch+1} Summary - Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        wandb.log({\"epoch\": epoch + 1, \"val_accuracy\": val_acc})\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b761e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 1.4195, Batch Acc: 0.3125\n",
      "[Batch 20/216] Loss: 1.2221, Batch Acc: 0.5625\n",
      "[Batch 30/216] Loss: 1.0356, Batch Acc: 0.8125\n",
      "[Batch 40/216] Loss: 1.0292, Batch Acc: 0.7500\n",
      "[Batch 50/216] Loss: 0.9146, Batch Acc: 0.7500\n",
      "[Batch 60/216] Loss: 0.7935, Batch Acc: 0.6875\n",
      "[Batch 70/216] Loss: 0.7963, Batch Acc: 0.6250\n",
      "[Batch 80/216] Loss: 0.8409, Batch Acc: 0.6875\n",
      "[Batch 90/216] Loss: 0.5895, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.6541, Batch Acc: 0.8125\n",
      "[Batch 110/216] Loss: 0.7148, Batch Acc: 0.7500\n",
      "[Batch 120/216] Loss: 0.5692, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.5468, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.5291, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.6124, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.5130, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.4224, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.3592, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.4579, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.5623, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.4354, Batch Acc: 0.9375\n",
      "Epoch 1 Summary - Loss: 161.8296, Train Accuracy: 0.7753\n",
      "Validation Accuracy: 0.9097\n",
      "\n",
      "Epoch 2/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3237, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.4432, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.3930, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.4405, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.4098, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2274, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.2263, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.5047, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.3709, Batch Acc: 0.8125\n",
      "[Batch 100/216] Loss: 0.4607, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.4837, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.3371, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2145, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.3456, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3719, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.7180, Batch Acc: 0.7500\n",
      "[Batch 170/216] Loss: 0.4631, Batch Acc: 0.7500\n",
      "[Batch 180/216] Loss: 0.4938, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.3732, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.4331, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.4872, Batch Acc: 0.8125\n",
      "Epoch 2 Summary - Loss: 87.0067, Train Accuracy: 0.8778\n",
      "Validation Accuracy: 0.9120\n",
      "\n",
      "Epoch 3/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3387, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.3856, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.4694, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.1561, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.2997, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.5017, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.1898, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.5266, Batch Acc: 0.8125\n",
      "[Batch 90/216] Loss: 0.1591, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.3182, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2140, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1528, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.4011, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.3051, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.3055, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.5865, Batch Acc: 0.8125\n",
      "[Batch 170/216] Loss: 0.2056, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.5633, Batch Acc: 0.8125\n",
      "[Batch 190/216] Loss: 0.1774, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.3855, Batch Acc: 0.8125\n",
      "[Batch 210/216] Loss: 0.4042, Batch Acc: 0.8750\n",
      "Epoch 3 Summary - Loss: 67.9530, Train Accuracy: 0.9105\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 4/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1592, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.4157, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.0613, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1909, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.4163, Batch Acc: 0.8125\n",
      "[Batch 60/216] Loss: 0.4465, Batch Acc: 0.7500\n",
      "[Batch 70/216] Loss: 0.3279, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.4245, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.1787, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1761, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.2807, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.3677, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2750, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1871, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2651, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.2684, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1239, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1164, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1990, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.2497, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1878, Batch Acc: 1.0000\n",
      "Epoch 4 Summary - Loss: 58.5541, Train Accuracy: 0.9218\n",
      "Validation Accuracy: 0.9213\n",
      "\n",
      "Epoch 5/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2744, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.2684, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.2376, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1546, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.3624, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.3658, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.3806, Batch Acc: 0.8125\n",
      "[Batch 80/216] Loss: 0.1450, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.3310, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.2290, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2049, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.2379, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.0942, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1697, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.3645, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.1529, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.2799, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.0860, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0761, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2999, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.3028, Batch Acc: 0.9375\n",
      "Epoch 5 Summary - Loss: 53.8219, Train Accuracy: 0.9250\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 6/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4392, Batch Acc: 0.6875\n",
      "[Batch 20/216] Loss: 0.1089, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0662, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.3410, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.2428, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.2364, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.3076, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.0953, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0907, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2038, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2383, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.1148, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1219, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0820, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1698, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1047, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1404, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.5052, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.1013, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.2109, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.3545, Batch Acc: 0.8750\n",
      "Epoch 6 Summary - Loss: 46.7115, Train Accuracy: 0.9374\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 7/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0422, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1223, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1092, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0332, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1600, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.0686, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1903, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.4124, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.1558, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1170, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1722, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1646, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2014, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0822, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.2822, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0697, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1633, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1486, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1134, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2172, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.2372, Batch Acc: 0.9375\n",
      "Epoch 7 Summary - Loss: 42.1290, Train Accuracy: 0.9470\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 8/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3177, Batch Acc: 0.8125\n",
      "[Batch 20/216] Loss: 0.0658, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.4270, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.2506, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.2818, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.2791, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.1578, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.2756, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1605, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1170, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1008, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.2938, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2390, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1877, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0420, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1962, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.2487, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1500, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2200, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.2687, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0393, Batch Acc: 1.0000\n",
      "Epoch 8 Summary - Loss: 39.1771, Train Accuracy: 0.9531\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 9/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1680, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1390, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2185, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1796, Batch Acc: 0.8750\n",
      "[Batch 50/216] Loss: 0.1684, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2018, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1217, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1745, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1713, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1373, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.5253, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1747, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0715, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0632, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.3309, Batch Acc: 0.8125\n",
      "[Batch 160/216] Loss: 0.0921, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0794, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0745, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.5894, Batch Acc: 0.8125\n",
      "[Batch 200/216] Loss: 0.1049, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1558, Batch Acc: 1.0000\n",
      "Epoch 9 Summary - Loss: 35.9381, Train Accuracy: 0.9571\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 10/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3269, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.2518, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1383, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1448, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.3417, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.3577, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.1049, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1525, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.2631, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1090, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0894, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1415, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1162, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0914, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1982, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0937, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1310, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.2051, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.2413, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0687, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1070, Batch Acc: 0.9375\n",
      "Epoch 10 Summary - Loss: 34.1008, Train Accuracy: 0.9568\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 11/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0980, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.2049, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.1174, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1037, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1024, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0365, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1494, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1552, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1845, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.0787, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1631, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1464, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1114, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2646, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.1329, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2573, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1421, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0744, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.2438, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1667, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2324, Batch Acc: 0.9375\n",
      "Epoch 11 Summary - Loss: 31.6422, Train Accuracy: 0.9597\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 12/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1573, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0782, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0511, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1793, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0643, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0631, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1422, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1120, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0906, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.3271, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.1684, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0798, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1122, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.2695, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.0214, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0957, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1528, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1595, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.1958, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0900, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1563, Batch Acc: 0.9375\n",
      "Epoch 12 Summary - Loss: 30.3180, Train Accuracy: 0.9626\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 13/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0246, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.2048, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0605, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0616, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.2320, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1735, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.3377, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.5208, Batch Acc: 0.8750\n",
      "[Batch 90/216] Loss: 0.0603, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1055, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0625, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0623, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1953, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1745, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.2699, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0765, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1749, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0628, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0590, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.4400, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.0205, Batch Acc: 1.0000\n",
      "Epoch 13 Summary - Loss: 29.0344, Train Accuracy: 0.9650\n",
      "Validation Accuracy: 0.9306\n",
      "\n",
      "Epoch 14/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.4289, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.0912, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0590, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1319, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0861, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0348, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1349, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0743, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0889, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0816, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0670, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1138, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1869, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.2310, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0302, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1849, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0363, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0203, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0937, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2151, Batch Acc: 0.8750\n",
      "[Batch 210/216] Loss: 0.0720, Batch Acc: 1.0000\n",
      "Epoch 14 Summary - Loss: 26.4774, Train Accuracy: 0.9690\n",
      "Validation Accuracy: 0.9317\n",
      "\n",
      "Epoch 15/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0648, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1013, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0578, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0736, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.2319, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.0858, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0421, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0895, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0545, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.3053, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.2105, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1718, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.2507, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1848, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0453, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0795, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0787, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1841, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.1810, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0945, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2159, Batch Acc: 0.9375\n",
      "Epoch 15 Summary - Loss: 24.4818, Train Accuracy: 0.9710\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 16/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.2000, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0393, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0245, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1215, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.1355, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.2007, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1777, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0651, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1066, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0820, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0191, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0575, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.2121, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0830, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1218, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0645, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0898, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1122, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1211, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1693, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0683, Batch Acc: 1.0000\n",
      "Epoch 16 Summary - Loss: 26.7010, Train Accuracy: 0.9690\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 17/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0978, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0695, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1161, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0487, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1054, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2117, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.0723, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0763, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1478, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.0570, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1851, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0476, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1739, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0482, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0832, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0960, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.2056, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.2140, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.0615, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1155, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1085, Batch Acc: 1.0000\n",
      "Epoch 17 Summary - Loss: 23.4856, Train Accuracy: 0.9722\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 18/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0494, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0817, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0460, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0535, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0401, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0154, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0346, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0714, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1460, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0740, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.2303, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0614, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0529, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0388, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1077, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0654, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0478, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0151, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0615, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2232, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1975, Batch Acc: 0.9375\n",
      "Epoch 18 Summary - Loss: 22.8436, Train Accuracy: 0.9748\n",
      "Validation Accuracy: 0.9340\n",
      "\n",
      "Epoch 19/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1226, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0889, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0603, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0151, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0428, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1658, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1441, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1316, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0285, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0812, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0648, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1689, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.0556, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1150, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0334, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0493, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.2164, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0362, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0559, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1298, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2654, Batch Acc: 0.9375\n",
      "Epoch 19 Summary - Loss: 21.9018, Train Accuracy: 0.9713\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 20/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0204, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1469, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.1942, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.0256, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0636, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0847, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0497, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1216, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0813, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2718, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.0475, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0350, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.3587, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.1055, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0699, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1101, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1388, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0609, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0341, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0451, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0379, Batch Acc: 1.0000\n",
      "Epoch 20 Summary - Loss: 19.5626, Train Accuracy: 0.9765\n",
      "Validation Accuracy: 0.9340\n",
      "\n",
      "Epoch 21/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0519, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1201, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0194, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0513, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0323, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0827, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0154, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0545, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0324, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1693, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.0459, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.2581, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.0884, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.1133, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1297, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1426, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0310, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0389, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0577, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0672, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0506, Batch Acc: 1.0000\n",
      "Epoch 21 Summary - Loss: 21.1598, Train Accuracy: 0.9728\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 22/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0566, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1411, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0981, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1143, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1299, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0336, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0481, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0627, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0812, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0745, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0677, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1576, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1084, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0656, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0208, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0305, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.2887, Batch Acc: 0.8750\n",
      "[Batch 180/216] Loss: 0.0521, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0501, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0214, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1489, Batch Acc: 0.9375\n",
      "Epoch 22 Summary - Loss: 19.2676, Train Accuracy: 0.9780\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 23/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0952, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.3072, Batch Acc: 0.8125\n",
      "[Batch 30/216] Loss: 0.0608, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0773, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0723, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0408, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1316, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0588, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0593, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0697, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0583, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0237, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0452, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0837, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0715, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0851, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0517, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0795, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0506, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0826, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1116, Batch Acc: 0.9375\n",
      "Epoch 23 Summary - Loss: 19.2623, Train Accuracy: 0.9765\n",
      "Validation Accuracy: 0.9236\n",
      "\n",
      "Epoch 24/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1028, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0259, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0857, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0828, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0413, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0839, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0403, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0710, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0769, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0637, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1677, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0908, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0362, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1046, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1310, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1037, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0641, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0911, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1518, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.2118, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0375, Batch Acc: 1.0000\n",
      "Epoch 24 Summary - Loss: 17.9878, Train Accuracy: 0.9763\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 25/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0167, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1030, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0888, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0292, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0156, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0158, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1332, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0570, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1422, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1027, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0847, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0404, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1100, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0199, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0909, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1354, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.1405, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1100, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.0217, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1069, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0710, Batch Acc: 1.0000\n",
      "Epoch 25 Summary - Loss: 16.7273, Train Accuracy: 0.9818\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 26/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1284, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0153, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.4915, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.0392, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0591, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0500, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0195, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1143, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1835, Batch Acc: 0.8750\n",
      "[Batch 100/216] Loss: 0.0851, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0885, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1223, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0608, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0628, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0766, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0206, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0067, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0835, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0066, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0312, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0510, Batch Acc: 1.0000\n",
      "Epoch 26 Summary - Loss: 17.4722, Train Accuracy: 0.9783\n",
      "Validation Accuracy: 0.9201\n",
      "\n",
      "Epoch 27/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0875, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0163, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1323, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0625, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0515, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0492, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1328, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0526, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0683, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1101, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0670, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1607, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0529, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0866, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1759, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.0529, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0731, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.1958, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.0709, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1514, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0335, Batch Acc: 1.0000\n",
      "Epoch 27 Summary - Loss: 17.4670, Train Accuracy: 0.9768\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 28/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1168, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0636, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0460, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1344, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0395, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0601, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0145, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0693, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0917, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0188, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0495, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0427, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1126, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0266, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1626, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.1229, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0809, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0235, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0241, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.2203, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0358, Batch Acc: 1.0000\n",
      "Epoch 28 Summary - Loss: 15.7897, Train Accuracy: 0.9815\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 29/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0191, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1256, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0312, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0447, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1424, Batch Acc: 0.8750\n",
      "[Batch 60/216] Loss: 0.0769, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.0985, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0364, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0581, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0370, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0422, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0324, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0279, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0540, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0194, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0385, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0666, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0512, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0839, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0491, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0176, Batch Acc: 1.0000\n",
      "Epoch 29 Summary - Loss: 16.1238, Train Accuracy: 0.9797\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 30/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1112, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1831, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0359, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0565, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1293, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.0633, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0049, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0133, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0603, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0429, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0856, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0518, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0477, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0612, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0194, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0431, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0149, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0622, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0308, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0876, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1619, Batch Acc: 0.9375\n",
      "Epoch 30 Summary - Loss: 16.4651, Train Accuracy: 0.9791\n",
      "Validation Accuracy: 0.9236\n",
      "\n",
      "Epoch 31/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.3936, Batch Acc: 0.8750\n",
      "[Batch 20/216] Loss: 0.0312, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0265, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0305, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0309, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0604, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0859, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0438, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0515, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1208, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0636, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0494, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0429, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0472, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0243, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0890, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0531, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1520, Batch Acc: 0.8750\n",
      "[Batch 190/216] Loss: 0.0334, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0398, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0844, Batch Acc: 1.0000\n",
      "Epoch 31 Summary - Loss: 15.5814, Train Accuracy: 0.9809\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 32/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0507, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0195, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2487, Batch Acc: 0.8750\n",
      "[Batch 40/216] Loss: 0.0407, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1587, Batch Acc: 0.9375\n",
      "[Batch 60/216] Loss: 0.1715, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.0719, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0570, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0951, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1500, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1151, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0563, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1032, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0875, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.1090, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0626, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0276, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0713, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1456, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0728, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.1267, Batch Acc: 0.9375\n",
      "Epoch 32 Summary - Loss: 14.3745, Train Accuracy: 0.9818\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 33/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0268, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0077, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0132, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0654, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.1142, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0441, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0119, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0508, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0244, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.2072, Batch Acc: 0.8750\n",
      "[Batch 110/216] Loss: 0.1793, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0254, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1729, Batch Acc: 0.8750\n",
      "[Batch 140/216] Loss: 0.0263, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1766, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0492, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0364, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1070, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0172, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0284, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0613, Batch Acc: 1.0000\n",
      "Epoch 33 Summary - Loss: 14.3050, Train Accuracy: 0.9806\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 34/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0507, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0462, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1937, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0548, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0956, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0481, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0260, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0251, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0065, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0592, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0386, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0170, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0119, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0098, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1235, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.2242, Batch Acc: 0.8750\n",
      "[Batch 170/216] Loss: 0.5378, Batch Acc: 0.8125\n",
      "[Batch 180/216] Loss: 0.0370, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0615, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.1046, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0306, Batch Acc: 1.0000\n",
      "Epoch 34 Summary - Loss: 13.9877, Train Accuracy: 0.9829\n",
      "Validation Accuracy: 0.9190\n",
      "\n",
      "Epoch 35/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0552, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1005, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1093, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1853, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0202, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0557, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0122, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1041, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0253, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1699, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1654, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0257, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0490, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0244, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0596, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0177, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0941, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0404, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0832, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0141, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0461, Batch Acc: 1.0000\n",
      "Epoch 35 Summary - Loss: 13.9017, Train Accuracy: 0.9832\n",
      "Validation Accuracy: 0.9213\n",
      "\n",
      "Epoch 36/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0253, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1372, Batch Acc: 0.8750\n",
      "[Batch 30/216] Loss: 0.0698, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0844, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0288, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0192, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0267, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0078, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0052, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0565, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0622, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0421, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0488, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0052, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0267, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0064, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0289, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0261, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1060, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.1752, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0314, Batch Acc: 1.0000\n",
      "Epoch 36 Summary - Loss: 13.5432, Train Accuracy: 0.9847\n",
      "Validation Accuracy: 0.9259\n",
      "\n",
      "Epoch 37/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0842, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.1069, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0553, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0563, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0184, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2143, Batch Acc: 0.8750\n",
      "[Batch 70/216] Loss: 0.0285, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.1174, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.1803, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1837, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0629, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.1359, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.1125, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0329, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0066, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.1698, Batch Acc: 0.9375\n",
      "[Batch 170/216] Loss: 0.0176, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0074, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0556, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0156, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0095, Batch Acc: 1.0000\n",
      "Epoch 37 Summary - Loss: 13.1586, Train Accuracy: 0.9864\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 38/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0717, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0970, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.1339, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0376, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0640, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1152, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.0123, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0190, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0230, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1115, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1241, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0103, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1196, Batch Acc: 0.9375\n",
      "[Batch 140/216] Loss: 0.0910, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0638, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0652, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0521, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0366, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0508, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0220, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2228, Batch Acc: 0.8750\n",
      "Epoch 38 Summary - Loss: 13.7878, Train Accuracy: 0.9820\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 39/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0417, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0222, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0134, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0313, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0379, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0190, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0026, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0514, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1645, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0939, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.1765, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0269, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0196, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1141, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0250, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0033, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0244, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.1204, Batch Acc: 0.9375\n",
      "[Batch 190/216] Loss: 0.0378, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0087, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.2059, Batch Acc: 0.9375\n",
      "Epoch 39 Summary - Loss: 12.9118, Train Accuracy: 0.9832\n",
      "Validation Accuracy: 0.9248\n",
      "\n",
      "Epoch 40/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0414, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0062, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0184, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0686, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0218, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.1027, Batch Acc: 0.9375\n",
      "[Batch 70/216] Loss: 0.1776, Batch Acc: 0.8750\n",
      "[Batch 80/216] Loss: 0.0141, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0111, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0038, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0608, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0141, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0592, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0131, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0620, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0267, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0591, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0412, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.1154, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0450, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0814, Batch Acc: 1.0000\n",
      "Epoch 40 Summary - Loss: 12.6123, Train Accuracy: 0.9838\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 41/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0294, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0189, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0153, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0110, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0650, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0152, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1148, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0729, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0732, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1424, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.1377, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.1048, Batch Acc: 0.9375\n",
      "[Batch 130/216] Loss: 0.0422, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0185, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0707, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0954, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0185, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0512, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0209, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0624, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0121, Batch Acc: 1.0000\n",
      "Epoch 41 Summary - Loss: 12.8172, Train Accuracy: 0.9832\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 42/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0116, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0324, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0490, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0218, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0108, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.2587, Batch Acc: 0.8125\n",
      "[Batch 70/216] Loss: 0.0995, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0271, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.2656, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0188, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.3524, Batch Acc: 0.8750\n",
      "[Batch 120/216] Loss: 0.0354, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0326, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0188, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.1569, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.0345, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0272, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0424, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0422, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0203, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0033, Batch Acc: 1.0000\n",
      "Epoch 42 Summary - Loss: 13.8894, Train Accuracy: 0.9812\n",
      "Validation Accuracy: 0.9155\n",
      "\n",
      "Epoch 43/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.1189, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0230, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0102, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0306, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0431, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0369, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0166, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0117, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0288, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0094, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0446, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0078, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.1145, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0081, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.4683, Batch Acc: 0.8750\n",
      "[Batch 160/216] Loss: 0.0083, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1622, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0507, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0727, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0741, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.2164, Batch Acc: 0.9375\n",
      "Epoch 43 Summary - Loss: 12.9887, Train Accuracy: 0.9820\n",
      "Validation Accuracy: 0.9282\n",
      "\n",
      "Epoch 44/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0281, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0687, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.2855, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.1339, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0112, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0280, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.1543, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.1086, Batch Acc: 0.9375\n",
      "[Batch 90/216] Loss: 0.0074, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.1185, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0944, Batch Acc: 0.9375\n",
      "[Batch 120/216] Loss: 0.0311, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0048, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0377, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0235, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0524, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0289, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0097, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2647, Batch Acc: 0.8750\n",
      "[Batch 200/216] Loss: 0.0522, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0605, Batch Acc: 0.9375\n",
      "Epoch 44 Summary - Loss: 12.5228, Train Accuracy: 0.9820\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 45/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0339, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0164, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0671, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1445, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0393, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0792, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0211, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0096, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.1539, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.1056, Batch Acc: 0.9375\n",
      "[Batch 110/216] Loss: 0.0356, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0304, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0036, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1036, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0301, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0147, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1493, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0070, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0159, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0075, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1641, Batch Acc: 0.9375\n",
      "Epoch 45 Summary - Loss: 11.6056, Train Accuracy: 0.9861\n",
      "Validation Accuracy: 0.9178\n",
      "\n",
      "Epoch 46/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0727, Batch Acc: 0.9375\n",
      "[Batch 20/216] Loss: 0.0547, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.2146, Batch Acc: 0.9375\n",
      "[Batch 40/216] Loss: 0.0129, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0450, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0172, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0874, Batch Acc: 0.9375\n",
      "[Batch 80/216] Loss: 0.0132, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0990, Batch Acc: 0.9375\n",
      "[Batch 100/216] Loss: 0.0048, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0228, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0125, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0118, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0110, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0118, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0262, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.1323, Batch Acc: 0.9375\n",
      "[Batch 180/216] Loss: 0.0693, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.2572, Batch Acc: 0.9375\n",
      "[Batch 200/216] Loss: 0.0412, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0315, Batch Acc: 1.0000\n",
      "Epoch 46 Summary - Loss: 11.5636, Train Accuracy: 0.9858\n",
      "Validation Accuracy: 0.9213\n",
      "\n",
      "Epoch 47/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0246, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0255, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0324, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0526, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0676, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0362, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0180, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0142, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0519, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0420, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0098, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0259, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0262, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0167, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0064, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0101, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0161, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0166, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0187, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0634, Batch Acc: 0.9375\n",
      "[Batch 210/216] Loss: 0.0168, Batch Acc: 1.0000\n",
      "Epoch 47 Summary - Loss: 11.1759, Train Accuracy: 0.9870\n",
      "Validation Accuracy: 0.9225\n",
      "\n",
      "Epoch 48/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0104, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.1679, Batch Acc: 0.9375\n",
      "[Batch 30/216] Loss: 0.0430, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.2219, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0069, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0192, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0548, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0425, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0334, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0212, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0200, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0191, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0127, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1375, Batch Acc: 0.9375\n",
      "[Batch 150/216] Loss: 0.0247, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0232, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0498, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0272, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0042, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0120, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0713, Batch Acc: 0.9375\n",
      "Epoch 48 Summary - Loss: 11.4609, Train Accuracy: 0.9844\n",
      "Validation Accuracy: 0.9190\n",
      "\n",
      "Epoch 49/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0093, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0154, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0626, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.1206, Batch Acc: 0.9375\n",
      "[Batch 50/216] Loss: 0.0380, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0210, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0077, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0033, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0748, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0790, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0317, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.2183, Batch Acc: 0.8750\n",
      "[Batch 130/216] Loss: 0.0201, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.0289, Batch Acc: 1.0000\n",
      "[Batch 150/216] Loss: 0.0362, Batch Acc: 1.0000\n",
      "[Batch 160/216] Loss: 0.0665, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0371, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0459, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0123, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0366, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.0437, Batch Acc: 1.0000\n",
      "Epoch 49 Summary - Loss: 11.7770, Train Accuracy: 0.9852\n",
      "Validation Accuracy: 0.9271\n",
      "\n",
      "Epoch 50/50\n",
      "------------------------------\n",
      "[Batch 10/216] Loss: 0.0216, Batch Acc: 1.0000\n",
      "[Batch 20/216] Loss: 0.0517, Batch Acc: 1.0000\n",
      "[Batch 30/216] Loss: 0.0207, Batch Acc: 1.0000\n",
      "[Batch 40/216] Loss: 0.0358, Batch Acc: 1.0000\n",
      "[Batch 50/216] Loss: 0.0610, Batch Acc: 1.0000\n",
      "[Batch 60/216] Loss: 0.0733, Batch Acc: 1.0000\n",
      "[Batch 70/216] Loss: 0.0314, Batch Acc: 1.0000\n",
      "[Batch 80/216] Loss: 0.0053, Batch Acc: 1.0000\n",
      "[Batch 90/216] Loss: 0.0029, Batch Acc: 1.0000\n",
      "[Batch 100/216] Loss: 0.0135, Batch Acc: 1.0000\n",
      "[Batch 110/216] Loss: 0.0295, Batch Acc: 1.0000\n",
      "[Batch 120/216] Loss: 0.0252, Batch Acc: 1.0000\n",
      "[Batch 130/216] Loss: 0.0755, Batch Acc: 1.0000\n",
      "[Batch 140/216] Loss: 0.1731, Batch Acc: 0.8750\n",
      "[Batch 150/216] Loss: 0.0608, Batch Acc: 0.9375\n",
      "[Batch 160/216] Loss: 0.0046, Batch Acc: 1.0000\n",
      "[Batch 170/216] Loss: 0.0108, Batch Acc: 1.0000\n",
      "[Batch 180/216] Loss: 0.0065, Batch Acc: 1.0000\n",
      "[Batch 190/216] Loss: 0.0625, Batch Acc: 1.0000\n",
      "[Batch 200/216] Loss: 0.0007, Batch Acc: 1.0000\n",
      "[Batch 210/216] Loss: 0.1604, Batch Acc: 0.9375\n",
      "Epoch 50 Summary - Loss: 12.8235, Train Accuracy: 0.9832\n",
      "Validation Accuracy: 0.9213\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, epochs=config.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
