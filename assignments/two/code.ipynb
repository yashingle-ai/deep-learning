{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1df639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5471d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Using GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4332e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.cuda.is_available()\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f57f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\deep Learning\\pyTorch\\data\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation, use_bn, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        act = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh()\n",
    "        }[activation]\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            act,\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            act,\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(64) ,\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 12 * 12, 128),\n",
    "            act,\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf815a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layers, activation, use_bn, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        act = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh()\n",
    "        }[activation]\n",
    "\n",
    "        modules = []\n",
    "        in_features = 28 * 28\n",
    "\n",
    "        for units in layers:\n",
    "            modules.append(nn.Linear(in_features, units))\n",
    "            if use_bn:\n",
    "                modules.append(nn.BatchNorm1d(units))\n",
    "            modules.append(act)\n",
    "            modules.append(nn.Dropout(dropout))\n",
    "            in_features = units\n",
    "\n",
    "        modules.append(nn.Linear(in_features, 10))\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d971fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    history = {\"loss\": [], \"acc\": []}\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        correct, total, loss_sum = 0, 0, 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        history[\"loss\"].append(loss_sum / len(train_loader))\n",
    "        history[\"acc\"].append(correct / total)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92848d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    model_type = trial.suggest_categorical(\"model\", [\"cnn\", \"mlp\"])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"sigmoid\", \"tanh\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"Adam\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    use_bn = trial.suggest_categorical(\"batchnorm\", [True, False])\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 15)\n",
    "\n",
    "    if model_type == \"cnn\": \n",
    "        model = CNN(activation, use_bn, dropout).to(device)\n",
    "    else:\n",
    "        layers = trial.suggest_categorical(\"layers\", [[256], [512,256,128]])\n",
    "        model = MLP(layers, activation, use_bn, dropout).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) if optimizer_name == \"Adam\" \\\n",
    "        else optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train(model, optimizer, criterion, epochs)\n",
    "    acc = test(model)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835fdb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:18:53,046]\u001b[0m A new study created in memory with name: no-name-375672a2-6094-4540-9184-80716a6a5e05\u001b[0m\n",
      "\u001b[32m[I 2026-01-30 14:21:36,411]\u001b[0m Trial 0 finished with value: 0.8996 and parameters: {'model': 'cnn', 'activation': 'tanh', 'optimizer': 'SGD', 'lr': 0.0003178330254512856, 'dropout': 0.24404087376846434, 'batchnorm': True, 'epochs': 10}. Best is trial 0 with value: 0.8996.\u001b[0m\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256] which is of type list.\n",
      "  optuna_warn(message)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 256, 128] which is of type list.\n",
      "  optuna_warn(message)\n",
      "\u001b[32m[I 2026-01-30 14:24:43,643]\u001b[0m Trial 1 finished with value: 0.7405 and parameters: {'model': 'mlp', 'activation': 'sigmoid', 'optimizer': 'SGD', 'lr': 0.000397943697475911, 'dropout': 0.33796493382531634, 'batchnorm': True, 'epochs': 7, 'layers': [512, 256, 128]}. Best is trial 0 with value: 0.8996.\u001b[0m\n",
      "\u001b[32m[I 2026-01-30 14:29:34,365]\u001b[0m Trial 2 finished with value: 0.8648 and parameters: {'model': 'mlp', 'activation': 'sigmoid', 'optimizer': 'SGD', 'lr': 0.008146116505046581, 'dropout': 0.04927151692923132, 'batchnorm': True, 'epochs': 12, 'layers': [512, 256, 128]}. Best is trial 0 with value: 0.8996.\u001b[0m\n",
      "\u001b[32m[I 2026-01-30 14:32:18,013]\u001b[0m Trial 3 finished with value: 0.7435 and parameters: {'model': 'cnn', 'activation': 'sigmoid', 'optimizer': 'SGD', 'lr': 0.0005439932192807673, 'dropout': 0.36548660331921706, 'batchnorm': False, 'epochs': 11}. Best is trial 0 with value: 0.8996.\u001b[0m\n",
      "\u001b[32m[I 2026-01-30 14:33:46,549]\u001b[0m Trial 4 finished with value: 0.8897 and parameters: {'model': 'cnn', 'activation': 'tanh', 'optimizer': 'Adam', 'lr': 0.0012014857933556943, 'dropout': 0.15555990479304072, 'batchnorm': True, 'epochs': 6}. Best is trial 0 with value: 0.8996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8996\n",
      "Best Params: {'model': 'cnn', 'activation': 'tanh', 'optimizer': 'SGD', 'lr': 0.0003178330254512856, 'dropout': 0.24404087376846434, 'batchnorm': True, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
